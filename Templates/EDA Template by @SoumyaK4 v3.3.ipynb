{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc308621",
   "metadata": {},
   "source": [
    "<center><img src=\"https://github.com/SoumyaK4/SoumyaK4/blob/main/Logo%20B.png?raw=true\" width=\"120\" height=\"50\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199ed7f",
   "metadata": {},
   "source": [
    "<a name = TOC></a>\n",
    "# <u>Table of Contents</u>\n",
    "\n",
    "**1.** [**Introduction**](#Section1)<br>\n",
    "**2.** [**Problem Statement**](#Section2)<br>\n",
    "**3.** [**Installing & Importing Libraries**](#Section3)<br>\n",
    "**4.** [**Data Acquisition & Description**](#Section4)<br>\n",
    "**5.** [**Data Pre-profiling**](#Section5)<br>\n",
    "**6.** [**Data Pre-processing and Post-profiling**](#Section6)<br>\n",
    "**7.** [**Exploratory Data Analysis**](#Section7)<br>\n",
    "**8.** [**Summarization**](#Section8)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e637f",
   "metadata": {},
   "source": [
    "<a name = Section1></a>\n",
    "# 1. <u>Introduction</u>\n",
    "[To ToC](#TOC)\n",
    "\n",
    "- Use **minimum 3 points** and **3 images**\n",
    "\n",
    "<center><img width=40% src=\"https://raw.githubusercontent.com/insaid2018/PGPDSAI/main/03%20Term%203%20-%20EDA%20%26%20Data%20Storytelling/03%20Module%203/img/03%20mental-health.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec5ca4",
   "metadata": {},
   "source": [
    "<a name = Section2></a>\n",
    "# 2. <u>Problem Statement</u>\n",
    "[To ToC](#TOC)\n",
    "\n",
    "- MESAURABLE\n",
    "- PRECISE\n",
    "- CLEAR\n",
    "<center><img width=40% src=\"https://raw.githubusercontent.com/insaid2018/PGPDSAI/main/03%20Term%203%20-%20EDA%20%26%20Data%20Storytelling/03%20Module%203/img/04%20mental-health.png\"></center>\n",
    "\n",
    "\n",
    "### **Scenario**\n",
    "\n",
    "- **A scenario**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1854c",
   "metadata": {},
   "source": [
    "<a name = Section3></a>\n",
    "# 3. <u>Installing & Importing Libraries</u>\n",
    "[To ToC](#TOC)\n",
    "\n",
    "- 4 useful [EDA Libraries](https://towardsdatascience.com/4-libraries-that-can-perform-eda-in-one-line-of-python-code-b13938a06ae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00b560",
   "metadata": {},
   "source": [
    "### **3.1 Installing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7741e404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q datascience                                         # Package that is required by pandas profiling\n",
    "# !pip install -q pandas-profiling                                    # Library to generate basic statistics about data\n",
    "# !pip install -q autoviz                                             # Automatically Visualize any dataset\n",
    "# !pip install -q sweetviz                                            # Library to do EDA\n",
    "# !pip install -q dtale                                               # Easy way to view & analyze Pandas data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a5eeee",
   "metadata": {},
   "source": [
    "### **3.2 Upgrading Libraries**\n",
    "\n",
    "- **After upgrading** the libraries, you need to **restart the runtime** to make the libraries in sync. \n",
    "\n",
    "- Make sure not to execute the cell above (3.1) and below (3.2) again after restarting the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q --upgrade pandas-profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd7be6",
   "metadata": {},
   "source": [
    "### **3.3 Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39db247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import numpy as np                                                  # Importing for numerical data analysis\n",
    "import pandas as pd                                                 # Importing for panel data analysis\n",
    "# import dtale                                                        # Importing for profiling the dataset\n",
    "# pd.set_option('display.max_columns', None)                          # Unfolding hidden features if the cardinality is high\n",
    "# pd.set_option('display.max_colwidth', None)                         # Unfolding the max feature width for better clearity\n",
    "# pd.set_option('display.max_rows', None)                             # Unfolding hidden data points if the cardinality is high\n",
    "# pd.set_option('mode.chained_assignment', None)                      # Removing restriction over chained assignments operations\n",
    "# pd.set_option('display.float_format', lambda x: '%.2f' % x)         # To suppress scientific notation over exponential values\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# from collections import Counter                                     # For counting hashable objects\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt                                     # Importing pyplot interface using matplotlib\n",
    "import seaborn as sns                                               # Importin seaborm library for interactive visualization\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings                                                     # Importing warning to disable runtime warnings\n",
    "warnings.filterwarnings(\"ignore\")                                   # Warnings will appear only once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c035577",
   "metadata": {},
   "source": [
    "<a name = Section4></a>\n",
    "# 4. <u>Data Acquisition & Description</u>\n",
    "[To ToC](#TOC)\n",
    "\n",
    "- This dataset is obtained from a survey in 2014.\n",
    "\n",
    "| Records | Features | Dataset Size |\n",
    "| :-- | :-- | :-- |\n",
    "| 100 | 5 | 10 KB| \n",
    "\n",
    "\n",
    "| Id | Features | Description |\n",
    "| :-- | :--| :--| \n",
    "|01|**Timestamp**|Time the survey was submitted.|\n",
    "|02|**Age**|The age of the person.| \n",
    "|03|**Gender**|The gender of the person.|\n",
    "|04|**Country**|The country name where person belongs to.|\n",
    "|05|**state**|The state name where person belongs to.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd74fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''\n",
    "data = pd.read_csv(filepath_or_buffer=url, header = None)              # in case of no header in data, header = None\n",
    "data = pd.read_csv(url, encoding = \"ISO-8859-1\")                       # in case of encoding error, encoding = \"ISO-8859-1\"\n",
    "\n",
    "# headers = []                                   # headers list\n",
    "# data.columns = headers                         # to assign headers \n",
    "\n",
    "# data.to_csv(path)                              # to save df to csv \n",
    "\n",
    "print('Data Shape:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2beb98",
   "metadata": {},
   "source": [
    "### **4.1 Data Description**\n",
    "\n",
    "- In this section we will get **information about the data** and see some observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ce3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()\n",
    "# To include all data types\n",
    "# data.describe(include='all')      \n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459c6f8",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "\n",
    "- Some observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463205ee",
   "metadata": {},
   "source": [
    "### **4.2 Data Information**\n",
    "\n",
    "- In this section we will see the **information about the types of features**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "\n",
    "data['col_name'].value_counts()                # get unique vals from cat cols "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39396a5d",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "\n",
    "- Some observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b6f6f",
   "metadata": {},
   "source": [
    "---\n",
    "<a name = Section5></a>\n",
    "# 5. <u>Data Pre-Profiling</u>\n",
    "[To ToC](#TOC) <br>\n",
    "\n",
    "---\n",
    "\n",
    "- [List of Dataframe functions](https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp)\n",
    "- misssing values - .info()\n",
    "- outlier - BOXplot, describe\n",
    "- duplicates - .duplicated()\n",
    "- inconstancy in dtypes - know what the type should be, info can see what it actually is.\n",
    "- typos - check for value_counts() or unique()\n",
    "- format - check by unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc40ab",
   "metadata": {},
   "source": [
    "### **5.1 Checking for Missing Data**\n",
    "\n",
    "- In this section, we will identify missing data and check the proportion of it and take appropriate measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec918b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if values are missing - isnull() alt method\n",
    "data.isna().sum()                              \n",
    "\n",
    "# percentage of missing values\n",
    "print(data.isna().sum() * 100 / len(data))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67aef75",
   "metadata": {},
   "source": [
    "### **5.2 Checking for duplicate Datapoints and Features**\n",
    "\n",
    "- In this section, we will identify redundant data and check the proportion of it and take appropriate measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Contains how many Duplicate Rows?', data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95e003",
   "metadata": {},
   "source": [
    "### **5.3 Checking for Inconsistency in Data**\n",
    "\n",
    "- In this section, we will **identify inconsistency** in data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(data['engV'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(data['mileage'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a802ac",
   "metadata": {},
   "source": [
    "### **5.4 Checking for Outliers**\n",
    "\n",
    "- Check for outliers in our data - [Article](https://www.analyticsvidhya.com/blog/2021/05/feature-engineering-how-to-detect-and-remove-outliers-with-python-code/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6423e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting\n",
    "data['col1'].sort_values(ascending=True).head(1000)[500:530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='col1',y='col2',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167e6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,5))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(data['col1'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(data['col2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5647949d",
   "metadata": {},
   "source": [
    "#### using z-score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the Boundary Values\n",
    "print(\"Highest allowed\",data['engV'].mean() + 3*data['engV'].std())\n",
    "print(\"Lowest allowed\",data['engV'].mean() - 3*data['engV'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1acea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming outliers\n",
    "new_df = data[(data['engV'] < highest) & (data['engV'] > lowest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8674486f",
   "metadata": {},
   "source": [
    "#### using iqr method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27582ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view boxplot\n",
    "sns.boxplot(data['engV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91083d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding iqr\n",
    "percentile25 = data['engV'].quantile(0.25)\n",
    "percentile75 = data['engV'].quantile(0.75)\n",
    "\n",
    "# find upper and lower limit\n",
    "upper_limit = percentile75 + 1.5 * iqr\n",
    "lower_limit = percentile25 - 1.5 * iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18dfb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming outliers\n",
    "new_df = data[(data['engV'] < upper_limit) & (data['engV'] > lower_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b04fe4",
   "metadata": {},
   "source": [
    "#### using percent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding 99 and 1 percent\n",
    "upper_limit = data['engV'].quantile(0.99)\n",
    "lower_limit = data['engV'].quantile(0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6991badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimming outliers\n",
    "new_df = data[(data['engV'] <= upper_limit) & (data['engV'] >= lower_limit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ba4cc",
   "metadata": {},
   "source": [
    "### **5.5 Checking for Typos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fe57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['col1'].unique()                   # or value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434fecf0",
   "metadata": {},
   "source": [
    "### **5.6 Checking for Inconsistent Data Types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aa5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88c913",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "\n",
    "- **Something** observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6591b90",
   "metadata": {},
   "source": [
    "---\n",
    "<a name = Section6></a>\n",
    "# 6. <u>Data Pre-Processing and Post-profiling</u>\n",
    "[**To ToC**](#TOC) \n",
    "\n",
    "---\n",
    "- [List of Dataframe functions](https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp)\n",
    "- outlier - drop - dependent of the objective - contextual\n",
    "- duplicates - .drop_duplicates() - contextual\n",
    "- misssing values - fillna(mean/median/mode) or delete the row/column.\n",
    "- inconstancy in dtypes - .astype()\n",
    "- typos - replace\n",
    "- format - replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c31651c",
   "metadata": {},
   "source": [
    "### **6.1 Handling of Missing Data**\n",
    "\n",
    "- In this section, we will take appropriate measures for missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c21c0d",
   "metadata": {},
   "source": [
    "**Previous Observations:**\n",
    "\n",
    "- We can observe that following features are found to have missing values along with the proportions:\n",
    "\n",
    "|Feature|Object Type|Missing Proportion|Solution|\n",
    "|:--:|:--:|:--:|:--|\n",
    "|state|Object|40%|Replace with mode.|\n",
    "|self_employed|Object|1.43%|Replace with mode.|\n",
    "|work_interfere|Object|20.97%|Replace with mode.|\n",
    "|comments|Object|86.97%|Drop the feature.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value = data['col_name'].mode()[0]                                  # to replace with mean median or mode\n",
    "data['col_name'].fillna('value', axis=1, inplace=True)                # axis=0 for rows, can use custom value as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows containing missing values - for cols axis = 1\n",
    "data.dropna(inplace=True)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedacc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to replace missing value\n",
    "data.replace(missing_val, new_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f57408",
   "metadata": {},
   "source": [
    "### **6.2 Handling of Redundant Data**\n",
    "\n",
    "- In this section, we will take appropriate measures for redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start by first removing the duplicate rows\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40921af3",
   "metadata": {},
   "source": [
    "### **6.3 Handling of Inconsistent Data**\n",
    "\n",
    "- In this section, we will **take appropriate measures** for inconsistent data.\n",
    "\n",
    "- Previously, we observed that **Timestamp** feature was **incorrectly indentified** as Object, so, we will rectify it.\n",
    "\n",
    "- [Drop](https://www.w3schools.com/python/pandas/ref_df_drop.asp) not neeeded cols\n",
    "- To [typecast](https://www.w3schools.com/python/pandas/ref_df_astype.asp) datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date']= pd.to_datetime(data['Date'])                       # typecast the col to datetime\n",
    "df[[\"col1\"]] = df[[\"col1\"]].astype(\"float\")                      # typecasting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b320e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename cols\n",
    "data.rename(columns={'col1':'col2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d11f15",
   "metadata": {},
   "source": [
    "### **6.4 Handling of Outliers**\n",
    "\n",
    "- Drop or Keep, Depends on Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26afb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the outliers \n",
    "data = data[data['Age'] < 75 & data['Age'] > 18]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c685705",
   "metadata": {},
   "source": [
    "### **6.5 Handeling Typos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d916d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d843a9ab",
   "metadata": {},
   "source": [
    "### **6.6 Fixing Inconsistent Data Types**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32f7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872f70e1",
   "metadata": {},
   "source": [
    "### **Observations:**\n",
    "\n",
    "- **Something** observed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd938f",
   "metadata": {},
   "source": [
    "<a name = Section7></a>\n",
    "# 7. <u>Exploratory Data Analysis</u>\n",
    "[**To ToC**](#TOC)\n",
    "\n",
    "#### Asking 15+-5 - relevant, reasonable, non vague questions<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea75caac",
   "metadata": {},
   "source": [
    "### 7.1 Uni-variate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb9206d",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8015201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14c4982c",
   "metadata": {},
   "source": [
    "### 7.2 Bi-variate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f35529",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6bec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74210d48",
   "metadata": {},
   "source": [
    "### 7.3 Multi-variate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079648c2",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ac9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5af314b8",
   "metadata": {},
   "source": [
    "<a name = Section8></a>\n",
    "# 8. <u>Conclusion & Summarization</u>\n",
    "[To ToC](#TOC)\n",
    "\n",
    "##### P-R-E-P approach to represent Actionable Insights we extracted out of Analysis\n",
    "- P - Point - Describe the POINT (Actionable Insight)\n",
    "- R - Reason - Rationale behind the stated POINT (Actionable Insight)\n",
    "- E - Example - Support the POINT with an EXAMPLE\n",
    "- P - Point - Converge back to POINT (Actionable Insight)\n",
    "\n",
    "- **<h4>Conclusion</h4>**\n",
    "\n",
    "- From a **state point of view**, **California leads the chart** when run down the analysis.\n",
    "\n",
    "  - **48.1%** of **males**, **70%** of **females**, and **88%** of **trans** were found to have **sought treatment** concerning the overall survey.\n",
    "\n",
    "  - The following set of **parameters** are found to be **affecting mental health** the most and thus requires treatment:\n",
    "    - Age\n",
    "    - Family history,\n",
    "\n",
    "-  **<h4>Actionable Insights</h4>**\n",
    "\n",
    "  - There should be an **awareness program** about mental health and its effects.\n",
    "\n",
    "  - Relationship **Managers** **should be supportive** with the right guidance towards their employees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868240c4",
   "metadata": {},
   "source": [
    "# <u>Code Dump</u>\n",
    "[To ToC](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a2e6c",
   "metadata": {},
   "source": [
    "### pearson corr\n",
    "correlation between 2 cont int variables\n",
    "- **corr coefficient** \n",
    " - close to +1 = large positive corr\n",
    " - close to -1 = large negative corr\n",
    " - close to 0 = no corr\n",
    "- **p-value**\n",
    " - < 0.001 = strong\n",
    " - < 0.05 = moderate\n",
    " - < 0.1 = weak\n",
    " - > 0.1 = not certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e990dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering\n",
    "data[data['col_name']>='value']\n",
    "\n",
    "# filtering and displaying specefic cols\n",
    "data[data['col_name']>='value']['col_name2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa09610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby col_name with mean of col_name2 and sort in descending order\n",
    "data.groupby('col_name')['col_name2'].mean().sort_values(ascending=False)\n",
    "\n",
    "# groupby function to find the average \"col1\" based on \"col2\"\n",
    "data[['col1','col2']].groupby(['col2'],as_index= False).mean()\n",
    "\n",
    "# plotting the above condition\n",
    "sns.barplot(x='col_name', y='col_name2', data=data)\n",
    "plt.title('Title')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a685610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display top 10 col_name values with col_name2.....col_name_n\n",
    "temp = data.nlargest(10, 'col_name')[['col_name','col_name2', 'col_name3']]\n",
    "\n",
    "# plot - hue(bar colors) = col_name3\n",
    "sns.barplot(x='col_name', y = 'col_name2', data = temp, hue='col_name3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e45c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display no of times an unique value occurred\n",
    "data.col_name.value_counts()\n",
    "\n",
    "# plot\n",
    "sns.countplot(x='col_name', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1791c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is col_name affected by col_name2?\n",
    "sns.scatterplot(x='col_name2', y = 'col_name', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96626298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count specefic values in an object feature\n",
    "# case = True for case sensitive\n",
    "len(data['col'].str.contains('value', case=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18805d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(data['col1']), max(data['col1']), 4)     # 4 for creating 3 equal spaced bins\n",
    "bin_names = ['low', 'mid', 'high']\n",
    "# create col for binned val\n",
    "data['binned_vals'] = pd.cut(df['col1'], bins, labels=bin_names, include_lowest=True)\n",
    "# use histogram for viz of the bins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
